# 决策树介绍
&emsp;&emsp;对决策树有过初步了解的人对决策树应该有个初步概念，决策树就是将各种属性根据在当前条件下，计算出划分结果最有利的属性，并将该属性做为划分属性，以此类推，直到所有的属性都划分完毕。其中如何确定该属性对于划分结果是最有利？这个需要用到信息熵的概念，即通过计算条件熵H(Y|X)(表示在已知随机变量X的条件下随机变量Y的不确定性)，选择不确定性最低的属性做为最优划分属性。
## 信息熵概念
&emsp;&emsp;什么是信息熵?信息熵是用来表示信息量大小的度量，即表示随机变量不确定性的度量。类似于速度用来表示物体运动快慢的度量。那么这个信息熵是如何计算的。因为信息熵是信息量的平均值，我们先来看一下信息量的计算公式：
$$I(a_i)=p(a_i)log_2 \frac{1}{p(a_i)}$$
- 其中$P (a_i)$表示 $a_i$事件发生的概率
假设一个事件有n种结果，每种结果的概率为$P(X = x_i) = p_i, i = 1,2,...,n$
则该随机变量X的熵定义为:

$$I(a_1,a_2,...,a_n) = \sum ^{n}_{i=1}{I(a_i)} =  \sum ^{n}_{i=1}{p(a_i)log_2 \frac{1}{p(a_i)}}$$
## 信息增益
对于熵的概念直观理解，熵是热力学里面的概念，表示运动的不确定性，熵越大，不确定性不大，在这里，熵同样表示随机变量的不确定性。
假设有随机变量(X,Y)，其联合概率分布为:
$$P(X = x_i,Y = y_j) = p_{ij},   i = 1,2,...,n; j=1,2,...,m$$ 
条件熵H(Y|X)：表示在已知随机变量X的条件下随机变量Y的不确定性，定义为X给定条件下Y的条件概率分布的熵对X的数学期望。
$$ H(Y|X) = \sum^{n}_{i=1}{p_i}H(Y|X = x_i) $$
信息增益:特征A对训练数据集D的信息增益，g(D,A),定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差,即
$$ g(D,A) = H(D) - H(D|A)$$
而在决策树中我们将信息增益最大的属性做为最有属性。